{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "c2a12acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import jax.numpy as jnp\n",
    "from jax import grad\n",
    "from tqdm.auto import tqdm\n",
    "from src.pdf import *\n",
    "\n",
    "names = [r'$x$',r'$y$']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "f2f59061",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Potential(q, L):\n",
    "    \"\"\"\n",
    "    Compute the potential energy U(q) = -ln(L(q)) in JAX function form.\n",
    "    Parameters\n",
    "    ----------\n",
    "    q : array-like\n",
    "        Position, in parameter space.\n",
    "    L : callable\n",
    "        Function of a probability distribution P(q) related to Hamiltonian H(q, p).\n",
    "        This is what we want to sample from. We hoped to use \"P\" for parameter\n",
    "        name, but this will cause ambiguity with the Potential name.\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        Negative log-potential energy at position q.\n",
    "    \"\"\"\n",
    "    return -jnp.log(L(q))\n",
    "def Kinetic(p, minv):\n",
    "    \"\"\"\n",
    "    Compute the kinetic energy K(p) = 0.5 * (p^T M^{-1} p) in JAX function form.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    p : array-like\n",
    "        Momentum vector.\n",
    "    mass : array-like\n",
    "        Mass matrix. We already considered higher-dimensional momentum \n",
    "\t\tvectors. So that the mass is also a matrix, where only the diagonal \n",
    "\t\tentries are non-zero.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        Kinetic energy corresponding to momentum p.\n",
    "    \"\"\"\n",
    "    return 0.5 * p @ minv @ p   # = 0.5 * (p^T M^{-1} p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "3c90df72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Leapfrog(q0, p0, dt, Nsteps, L, Massinv):\n",
    "    \"\"\"\n",
    "    A leapfrog integrator solving for Hamiltonian (H) in the kick-drift-kick scheme.\n",
    "\tThis was introduced in Lecture 9 (Mon, Sep 29, 2025):\n",
    "\thttps://ua-2025q3-astr501-513.github.io/notes-9/#leapfrog-verlet-integrator\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    q0 : array-like\n",
    "        Initial position.\n",
    "    p0 : array-like\n",
    "        Initial momentum.\n",
    "    dt : float\n",
    "        Time size for every step.\n",
    "    Nsteps : int\n",
    "        Number of leapfrog total integration steps.\n",
    "    L : callable\n",
    "\t\tFunction of a probability distribution P(q) related to Hamiltonian H(q, p).\n",
    "    Mass : array-like\n",
    "        Mass matrix.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    (array, array)\n",
    "        (Position, momentum) tuple (q, p) giving the new position and momentum after integration.\n",
    "    \"\"\"\n",
    "    q = q0\n",
    "    dUdq = grad(Potential, argnums=0)\n",
    "\t\n",
    "    # Half-step momentum update\n",
    "    p = p0 - 0.5 * dt * dUdq(q, L) # Half-step\n",
    "    \n",
    "    # Full steps\n",
    "    for _ in range(Nsteps - 1):\n",
    "        q = q + dt * Massinv @ p      # Full-step\n",
    "        p = p - dt * dUdq(q, L)    # Full-step \n",
    "    \n",
    "    # Final position and half momentum update\n",
    "    q = q + dt * Massinv @ p          # Final full-step\n",
    "    p = p - 0.5 * dt * dUdq(q, L)  # Final half-step\n",
    "    \n",
    "    return q, -p  # TODO: Why negative?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "86869c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Sampler(q0, dt, Nsteps, L, Mass, Massinv):\n",
    "    \"\"\"\n",
    "    HMC sampler using leapfrog integrator.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    q0 : array-like\n",
    "        Initial position.\n",
    "    dt : float\n",
    "        Time size for every step.\n",
    "    Nsteps : int\n",
    "        Number of leapfrog total integration steps.\n",
    "    L : callable\n",
    "        Likelihood function.\n",
    "    Mass : array-like\n",
    "        Mass matrix.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    array-like\n",
    "        New sample position after Metropolis acceptance test.\n",
    "    \"\"\"\n",
    "    # Draw a random momentum vector from the Normal distribution: p ~ N(0, Mass)\n",
    "    p0 = jnp.array(np.random.multivariate_normal(np.zeros_like(q0), Mass))\n",
    "\n",
    "\t# Compute new (q, p) after given N steps from the leapfrog integration\n",
    "    q, p = Leapfrog(q0, p0, dt, Nsteps, L, Massinv)\n",
    "\n",
    "    # Compute initial and final energies\n",
    "\t# Reason: In fact, in numerical calculation, we cannot compute the true path of (q, p)\n",
    "\t#         with the constant Hamiltonian/energy. Check what the difference is below. \n",
    "    Uinit  = Potential(q0, L)\n",
    "    Ufinal = Potential(q, L)\n",
    "    Kinit  = Kinetic(p0, Massinv)\n",
    "    Kfinal = Kinetic(p, Massinv)\n",
    "\n",
    "    # Metropolis acceptance criterion\n",
    "    # Reason: If ideally, our computed (q_new, p_new) has the same energy, we are\n",
    "    #         very happy to accept this (q_new, p_new). Otherwise (also in most cases), \n",
    "    #         we still accept it but with a likelihood of ~ min(1, e^{-ΔH}).\n",
    "    if np.random.uniform(0,1) < np.exp(Uinit - Ufinal + Kinit - Kfinal):\n",
    "        return q  # Accept\n",
    "    else:\n",
    "        return q0 # Reject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "7c2b917b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "f99b8278",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Hmc(q0, Nsamples, dt, Nsteps, L, Mass, burnin=0, Nwalkers=16):\n",
    "    \"\"\"\n",
    "    Main Hamiltonian Monte Carlo (HMC) sampling.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    q0 : array-like\n",
    "        Initial position (a parameter vector).\n",
    "    Nsamples : int\n",
    "        Number of samples.\n",
    "    dt : float\n",
    "        Time size for every leapfrog integration step.\n",
    "    Nsteps : int\n",
    "        Number of leapfrog steps per sample.\n",
    "    L : callable\n",
    "        Likelihood distribution function of position/parameter.\n",
    "    Mass : array-like\n",
    "        Mass matrix.\n",
    "    burnin : int, optional\n",
    "        Number of initial samples to discard. Default is 0.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray\n",
    "        Array of accepted samples after burn-in.\n",
    "    \"\"\"\n",
    "        \n",
    "    minv = jnp.linalg.inv(Mass) # = M^{-1}\n",
    "    def run_chain(q0, Nsamples, dt, Nsteps, L, Mass, minv, burnin, show_pbar=False, total_samples=None):\n",
    "        q_current = q0\n",
    "        samples = []\n",
    "        \n",
    "        pbar = tqdm(total=total_samples) if show_pbar else None\n",
    "        \n",
    "        for _ in range(Nsamples + burnin):\n",
    "            q_current = Sampler(q_current, dt, Nsteps, L, Mass, minv)\n",
    "            samples.append(q_current)\n",
    "            if pbar is not None:\n",
    "                pbar.update(Nwalkers)\n",
    "        \n",
    "        if pbar is not None:\n",
    "            pbar.close()\n",
    "        \n",
    "        return np.array(samples[burnin:])\n",
    "\n",
    "    total_samples = (Nsamples//Nwalkers + burnin) * Nwalkers\n",
    "\n",
    "    results = Parallel(n_jobs=Nwalkers) \\\n",
    "        (delayed(run_chain)(q0, Nsamples//Nwalkers, dt, Nsteps, L, Mass, minv, burnin, \n",
    "                            show_pbar=(i==0), total_samples=total_samples) \\\n",
    "        for i in range(Nwalkers))\n",
    "\n",
    "    samples = np.concatenate(results)\n",
    "\n",
    "    # Remove burn-in samples\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7aabea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 720/5152 [00:15<01:43, 42.71it/s]"
     ]
    }
   ],
   "source": [
    "from getdist import MCSamples, plots\n",
    "\n",
    "# Ex. Donut\n",
    "samples = Hmc(jnp.array([0.0, 0.0]), 5000, 0.1, 30, Banana, jnp.array([[1.0, 0.0],[0.0, 1.0]]),10)\n",
    "samps = MCSamples(samples=samples, names=names)\n",
    "g = plots.get_subplot_plotter()\n",
    "g.triangle_plot([samps], filled=True, smooth_scale_1D=1., smooth_scale_2D=1.)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mapper",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
